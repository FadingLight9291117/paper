# 综述：无标定(uncalibrated)图像的3D人脸重建技术

## 摘要

当前(Recently)，大量的研究聚焦于将3D数据结合(incorporation)进人脸分析以及它的应用。尽管(despite)能更加准确的表示人脸特征，然而3D人脸图像却比2D图像更加复杂。因此，人们投入(invest)了大量的努力(effort)去开发从无标定(uncalibrated)2D图像上重建3D人脸的系统。然而，2D到3D人脸重建问题是不存在的(ill-posed)，因此需要先验知识(prior knowledge)来限制解空间(solutions space)。在本工作中，我们回顾(review)了近十年中被提出的3D人脸重建的方法，聚焦于那些仅使用在不受控条件下拍摄(capture)的2D图片的方法。我们基于添加先验知识的技术，对所提出的方法进行了分类，考虑了三个主要策略(strategies)，即(namely)统计学模型拟合，测光法(photometry)和深度学习，并且分别进行了回顾。此外，考虑到(given)统计学的作为先验知识的3D人脸模型的相关性(relevance)，我们解释其构造过程并提供了一份最流行的、公开的(publicly)、可用的3D人脸模型的清单。在彻底(exhaustive)地研究了从2D到3D的人脸重建方法之后，我们观察到(observe)最近几年深度学习方法正在急速地发展，成为标准方法以替代(in replacement of)广泛的(widespread)统计学模型拟合。与其他两种策略(strategies)不同的是，基于测光法的方法有所减少，因为相较于统计学模型拟合和深度学习方法，需要强有力的基本(underlying)假设(assumptions)来限制重建的质量。这篇回顾还确定(identifiy)了当前的挑战，并为未来的研究提供了一些途径(avenues)。

*关键词*：3D人脸重建，3D人脸成像，3D形变模型



## 1. 引言

​	面部分析已经在许多不同应用中得到了广泛的应用(exploited)，包括人机交互，安全，动画(animation)，甚至是健康。在这个领域的一个最新趋势是结合(incorporate)3D数据，以克服(overcome)普遍存在的(ubiquitous)2D面部分析的一些内在(intrinsic)问题。由于人脸的3D性质(nature)，一张2D图像不足以准确地捕获人脸的几何形状(geometry)，这是因为2D图像缺失(collapse，折叠)了一个维度(dimension)。此外(furturemore)，3D成像提供了一种姿态和照明不变(invariant)的面部几何图形的表示(representation)，这就是2D成像的两个主要不便(inconvenience)之处。

​	3D人脸分析系统系统带来的有利条件以更加复杂的成像过程为代价，这通常会限制它的使用范围(scope)。3D人脸信息通常是使用立体视觉(stereo-vision)系统、3D激光(laser)扫描仪(scanner)和RGB-D摄像机(cameras)来捕获的。前两个方法可以捕获高质量(quality, quantity)的面部扫描，但是需要控制环境和昂贵的机器(machinery)。相反(in constrast)，RGB-D摄像机更廉价并且更容易使用，但是扫描结果的质量不高。

​	一种吸引人的(appealing, appeal, 呼吁，恳求，对...有吸引力)替代捕获3D人脸扫描的方法是从未标定的2D图像中估计出人脸几何形状。这一从2D到3D的人脸重建的替代方案，是为了融合捕获2D图像的简易性和人脸的3D几何形状表示的优点。

​	即使这个方法很吸引人的(attractive)，但是它还是有天生的(inherently)缺陷(ill-posed)：单个(individual)面部几何形状、头部的姿态和它的纹理(texture，质地，结构，本质)(包括照明度(illumination，照明，阐明，照明度)和颜色)都必须从一个单一的照片中恢复(recover)，这就导致(lead to)了一个未确定的(underdetermined)问题。结果(as a consequence)，从2D到3D人脸重建技术就有了一些模棱两可的问题——因为单一的2D图片可以产生不同的3D人脸，并且很难确定(determine)哪一个是正确的几何图形。

​	最近的方法进展(progress)有助于实现了非常(remarkablely, 引人注目的)令人信服(convincing, convince, 说服)的重建工作，使得在各种领域使用从2D到3D人脸重建技术成为可能。一些方法甚至能够恢复(recover)本地的细节，比如皱纹，或者重建了在极端条件下的3D人脸图像，例如遮挡(occlusion)或者较大的头部姿态。

​	从2D到3D重建方法成功的一个关键是添加一个先验知识来解决问题中的歧义问题。在最近十年，我们可以区分出三种添加先验知识的策略，也就是(namely)，统计学模型拟合，光度测量法，以及深度学习。第一种方法，先验知识被编码进了3D面部模型中，该模型由一组3D面部扫描的集合构建，它被拟合进了输入的图像中。第二种方法，光度测量法结合了一个3D模板或是一个3D面部模型来估计面部表面的法线(normal)。基于这个策略的方法通常使用多张照片的信息，这进一步(further)限制(constrain)了这个问题。第三种方法，通过深度神经网来实现从2D到3D的映射，只要给定(given)适当的(appropriate)训练集，就可以学习到与几何形状和人脸外观(appearance)关联的必要先验知识。

​	在这个工作中，我们回顾了近期的从一个或更多未标定的2D图像中重建人脸的研究。对于上述三种主要的策略，我们总结(summary)、比较和讨论了近十年提出的最相关的方法。我们也会为所有提出的方法引入一个共同的数学框架，其符号在附录A中总结。

​	尽管也有其他人回顾了这个领域，但是他们都没有深入的(in-depth)和最新的(up-to-date)的研究关于最先进的(state-of-the-art)从2D到3D人脸重建技术 。Stylianou和Lanitis展示(present)了从2D图像到3D人脸重建的综述，但是他们仅仅研究到2009年。最近十年这个领域的迅速扩张以及深度学习技术的兴起(emergence)使得他们的工作已经废弃(obsolete)了。此外(also)，Levine和Yu也展示回顾了这一主题，但是他们仅仅局限(narrow，变狭窄，缩小)于从单一图像上重建，仅仅聚焦于人脸重建的模型拟合方法。最近以来(more recently)，Zollh¨ofer等人展示了另外一种从单一图片重建的方法，但是他们仅仅聚焦于基于优化(optimisatino-based)的方法，也遗失了基于深度学习和光度测量法的方法。最后Eggeret等人将这项工作更新到了2020年，他们展示了一个非常广泛的综述，尤其是聚焦于统计学面部模型，回顾了3D数据采集(acquisition)，3D面部模型构造，以及2D图像生成。尽管他们的工作包含了3D人脸重构，但是仅仅回顾了最为应用的3D人脸重建，并且他们聚焦于单一图像的重建（包括RGB和RGB-D）和模型拟合，简略地(briefly)讨论了深度学习方法。其他关于3D人脸重建的综述，比如Suen等人和Widanagamaachchi和Dharmaratne，他们研究了一般的策略，讨论他们的优势和劣势，但是没有更加深入的回顾其中最相关(relvent)的工作。因此，我们的回顾更新补充(complement)了已存在的综述，全面(comprehensive)完整的回顾了从2D到3D人脸重建的方法。

​	这项综述的其余(reminder)部分组织如下：在第2节中，我们首先介绍了最流行的构建统计学3D面部模型的方法，并且列出了已经被用于从2D到3D人脸重建工作的公共可用的方法。在第三节中，我们回顾了基于统计学模型拟合的方法。在第4和第5节中，我们分别(respectively)回顾了基于光度测量法和基于深度学习的方法.在第6节中，我们回顾了使用其他机器学习技术的方法，比如回归。最后，在第7节，我们回顾了从未标定图像中重建3D人脸的主要应用，并且在第8节中做出来总结。

## 2. 背景：统计学3D面部模型

​	如引言所述(stated)，2D到3D人脸重建是一个不适定(ill-posed)问题，因此它需要先验知识来解决原本不充分确定的解。

## 5. 深度学习方法

​	第3节和第4节中的3D人脸重建方法都使用模型来体现(embody)先验知识的。统计学模型拟合方法包含一个几何图形(通常还有纹理(texture))模型，光度测量法模拟(model)了人脸的反射率(reflectance)。相比之下(in contrast)，深度学习方法直接学习2D图像到3D人脸的映射，在训练的网络的权重中编码先验知识。

​	尽管深度学习在许多不同的应用中都是一个很强大(powerful)的工具，但是由于缺乏3D面部扫描的标(ground truth)，阻碍(hamper)了将其直接应用于3D人脸重建。但是，研究者们已经提出了不同的方法来生成和学习实际的(realistic)具有代表性的(representative)训练数据，设法克服(circumvente)缺失真实标注数据的阻碍(obstacle)。

​	在这一节中，我们展示并且比较了与3D人脸重建最相关的工作，这些工作都是使用深度学习作为主要工具。在学习过程中所涉及的许多元素之中(among)，我们考虑了三种具有代表性的，即(namely)，1）用于训练网络的训练集，2）学习框架，3）训练标准(criterion)。我们根据这3项组织章节。

​	根据上述各项，表5、6、7总结(summary)了回顾的每个深度学习工作的特性。训练集列指示该网络是否是通过3DMM来构建到真实图像的或者是根据3D人脸渲染(render)合(sy)成的图像，再或者二者都有。在学习框架这一列，指定(indicate)了四个指标：网络类型，网络层数、是否使用残差连接(skip connections)，以及学习过程是否是迭代的。如果一个网络是由$$A$$个网络，每个网络有$$B$$层组成，那么这个网络的层数为$$A*B$$；如果有n个网络$$B_1...B_n$$并行排列，那么表示为$$B_1//B_2//...//B_n$$。最后，训练标准(criterion)列表示(indicate)，损失函数是否是参数空间，3D空间或者是2D空间计算出来的。

#### 5.1. 训练集

​	正如我们上面所提及的，当将深度学习技术应用于2D到3D人脸重建时，最大的障碍(obstacle)是训练集的缺乏，因为深度学习算法需要得到(obtain)一个大量的3D面部扫描和对应2D图片，这是不切实际的。为了克服这个限制(limitation)，研究者们已经提出了构建合成(synthetic)训练集的技术，利用(take advantage of)预先构建的3DMM，以一种更加可行的方法来得到(obtain)3D人脸。

​	我们可以区分三种主要的策略来构建合成的训练集。第一种指的是拟合&渲染，包括先拟合一个3DMM到真实图片，然后使用一个估计出的3D人脸渲染合成的图片。第二种，生成&渲染，通过来从3DMM中随机采样(sample)生成3D人脸，然后再次使用生成的3D人脸渲染合成到图片上。另一方面，最近几年出现了一种新的策略，包括(consist in)自监督训练，避免需要配对的2D-3D数据，以及因此需要构建合成数据集。这个方法基于三种主要的策略，分别在5.11、5.12和5.13节中回顾。然而，还有其他的一些工作使用拟合&渲染和生成&渲染来合成训练集，或者是使用真实数据。这些在5.1.4节中总结。

#### 5.1.1 拟合&渲染策略

​	正如上述所说，拟合&渲染策略是将一个3DMM拟合到真实图片上。然后，放大与3D人脸对应的2D图像的变异性，使用估计出的3D人脸创造合成的图像。即使这个策略允许训练集中有真实的2D图像，这也有助于网络在测试时性能更好，但是它也有缺点(weakness)。一个缺点是，深度学习方法训练的精度在很大程度上是由用于重建ground truth3D人脸的3DMM拟合算法决定的。换句话说，由于以用深度学习方法重建估计的3D人脸，它将学习复制(reproduce)3DMM拟合算法得到(obtain)的结果。然而(also)，深度学习的一个优点——能从训练集中学习到非线性的关系，受到了训练它的线性建模的数据的限制。一些工作已经努力克服这些限制，比如通过包含真实的数据集，从多张图片中训练，以及细化(refine，精炼)粗糙的(coarse)3D人脸重建。

​	Zhu等人第一次介绍了拟合&渲染策略。他们提出一种人脸分析(profile，轮廓，给...画侧面图)技术，被用于生成姿态跨度更大的图片，并创造了300W-LP(300w large poses)的数据库。他们首先通过[163]和[63]拟合3DMM，估计出给定人脸图像的3D网格。然后，旋转3D网格并投影到图片上，来生成一张与原始图片相似但是姿态较大的合成图片。这个300W-LP数据库已经被许多其他作者使用过，因为它包含真实的和有挑战性的人脸图像，并且带有3DMM的真实标注和投影参数。Galteri等人也遵守拟合&渲染策略，通过生成和Zhu等人类似的新姿态的图像来增强FRGC数据集。

​	Guo等人注意到了上述方法的缺点(shortcoming)，并且提出了一种管道，用于构造带有细节的3D人人脸训练集和逼真的(photo-realistic)2D图像。若要这样做(to do so)，他们从使用3DMM拟合方法获得的粗糙的(coarse)面部形状估计出了每个顶点的位移(displacement)，然后混合(blend)由3DMM估计出的反照率(albedo)，以获得尽可能接近原始图片的渲染图像。一旦渲染完毕，就将转变它们生成更加真实的2D图像。

​	与渲染&拟合策略密切相关，一些其他人提出了拟合3DMM到图像的方法，而无需渲染。Jourabloo和Liu等人，Chinaev等人，Chaudhuri等人和Li等人为每个训练集独立地估计了3DMM的参数，然而(whereas)Liu等人和Tran等人结合了从同一个人的多张图像提取出的参数。Liu等人拟合了多图像的3DMM，对相似对象的所有图像执行(enforce)共同的形状参数，并且独立地估计每张图像由于表情产生的形状变形(deformation)。相比之下(in contrast)，Tran等人计算从同一个人的多张图片计算估计的加权平均(weighted average)形状和纹理参数。所得到的参数是对象的所有图像的真实值标签(ground truth)。与所有工作不同的是，Yoon等人使用[163]创造的非线性人脸模型，[163]使用自动解码器网络来学习带纹理的3D人脸的非线性表示，并且将[163]在训练阶段拟合的图像作为训练集。这个训练集包括来自不同角度2D视频(连续的(consecutive)2D图像)，以及相应的模型参数。

#### 5.1.2 生成&渲染

​	生成渲染策略在于从3DMM中采样而获得3D人脸的真实值标签(ground truth)，然后在不同的条件下渲染3D人脸创建对应的2D图像。这个策略避免了使用辅助的(auxiliary)3DMM拟合算法，并且网络的学习能力没有因此别重建算法限制。然而，不像拟合&渲染策略，2D图像不是真实的，因为渲染过程完全是人工合成的，具有合成的背景，灯光条件，投影参数等。此外(Also)，这个策略没有克服从线性数据学习的缺点，因为仍然是使用3DMM创造标签真实值(ground truth)3D人脸。意识到这些缺点，遵循(follow)生成和渲染策略的工作提出了不同的方法来克服这些缺点，例如包含真实数据，向3d人脸中添加合成变形(deformation)，或者采用更加复杂的训练框架。

​	Richardson等人使用生成渲染策略，提出了一个弱透视(perspective)投影和Phong反射模型来渲染合成的图像。这个方法被[104,107,108]严格遵守。Richardson等人和Sela等人仅使用[100]生成的数据集来训练他们的网络，不像Dou等人那样使用公开可用的3D人脸数据集，即FRGC2数据库，BU-3DFR数据库。

​	与Richardson等人类似，Piao等人遵循生成&渲染策略来构建他们的训练集。然而，他们添加小的自由形式的变形到一些生成的3D人脸的鼻子和皮肤上。根据作者所说，这使他们能合成更多的真实面部形状，因为真实人脸也许不会被线性模型完全捕获到。

​	Sengupta等人和Genova等人用两阶段的方式(manner)训练他们的网络。Sengupta等人，在第一个阶段，使用生成&渲染技术合成的数据上训练了一个简单的网络。在第二个阶段，他们使用预训练的简单网络获得一组真实图像上的正常估计，反照率和灯光估计。训练集是由合成的3D-2D数据和带估计的正常，反照率和光照的2D真实图像组成的，训练集的目标是阻碍(prevent)网络产生琐碎的(trivial)解决方案。相比之下(in contrast)，Genova等人在每一个阶段都是用不同的训练集来训练网络。在第一个阶段，他们使用遵循生成&渲染策略合成的3D-2D数据，然而(whereas)在第二个阶段，他们仅在自动编码机架构中使用无标签的数据。

### 5.1.3 自监督

​	鉴于真实3D到2D对标签真实值(ground truth)数据的缺乏，以及训练合成(synthetic)数据的缺点，一种新的策略——自监督——引起了人们的注意。自监督的主要思想是通过在网络的最后一层添加一个渲染层来让数据自身提供监督信息。这个渲染层获取纹理3D人脸和通过主网络估计渲染的参数，并渲染出合成的图像。这允许(enable)通过最小化输入和渲染的图像之间的差异来端到端地训练网络，而无需3D人脸的标签真实值(ground truth)。一些工作用人工修改的图像来训练网络，以扩大照明度、姿态等变化范围，然而也有其他的工作使用真实图像。

​	此外，Zhou等人使用真实的3D面部扫描集合来训练自动编码机网络，他的解码器被用于图像到网格的编码器-解码器网络，并且Wu等人使用Zhu等人生成的300W-LP数据集，以全监督的方式(manner)预训练他们的网络。Sanyal等人和Wang等人也使用自监督的方式训练网络，但是不同于渲染合成图像，他们只是将关键点位置投影到图像平面上(plane)。

​	
